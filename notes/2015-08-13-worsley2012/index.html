<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>Notes: Worsley - 2012 - Multimodal learning analytics - Bodong Chen</title>
    <meta property="og:title" content="Notes: Worsley - 2012 - Multimodal learning analytics - Bodong Chen">
    

    
      
    

    

    
    

    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
<link rel="stylesheet" href="/css/custom.css" />

  </head>

  
  <body class="notes">
    <header class="masthead">
      <h1><a href="/">Bodong Chen</a></h1>

<p class="tagline">Crisscross Landscapes</p>

      <nav class="menu">
        <input id="menu-check" type="checkbox" />
        <label id="menu-label" for="menu-check" class="unselectable">
          <span class="icon close-icon">✕</span>
          <span class="icon open-icon">☰</span>
          <span class="text">Menu</span>
        </label>
        <ul>
        
        
        <li><a href="/">Home</a></li>
        
        <li><a href="/blog/">Blog</a></li>
        
        <li><a href="/cv/">Publications</a></li>
        
        <li><a href="/notes/">Open Scholar</a></li>
        
        <li><a href="/teaching/">Teaching</a></li>
        
        <li><a href="/%E5%8D%9A%E5%AE%A2/">博客</a></li>
        
        <li><a href="/index.xml">Subscribe</a></li>
        
        
        </ul>
      </nav>
    </header>

    <article class="main">
      <header class="title">
      
<h1>Notes: Worsley - 2012 - Multimodal learning analytics</h1>

<h3>
</h3>
<hr>


      </header>





<h2 id="references">References</h2>

<p><strong>Citekey</strong>: @Worsley2012</p>

<p>Worsley, M. (2012). Multimodal learning analytics. In Proceedings of the 14th ACM international conference on Multimodal interaction - ICMI ’12 (p. 353). New York, New York, USA: ACM Press. doi:10.<sup>1145</sup>&frasl;<sub>2388676</sub>.2388755</p>

<h2 id="notes">Notes</h2>

<p>Worsley&rsquo;s brief description of his plan of dissertation work.</p>

<h2 id="highlights">Highlights</h2>

<p>In order to develop a more appropriate measure and means for assessing SPBL I want to construct a complete picture of how learning takes place in SPBL environments through the use of multimodal learning interfaces and techniques. (p. 1)</p>

<p>Furthermore, this research builds on the work that I have done during the past three years which has found that there are meaningful cues in student speech [15][16][17], gaze [18], programming state [19]; epistemological beliefs and identity [20]; and in a combination of modalities [21][22]. It also builds on a number of published and unpublished research tools that enable: object tracking [23]; user localization [24]; and multi-modal data capture of collaborative work [25][26][27]. To this end, my previous research has looked at a variety of modalities in isolation, but as I move forward into my dissertation work I want to begin to better leverage the integration of different data streams in extended analyses of student learning. (p. 1)</p>

<p>will be studying high school and undergraduate students as they participate in engineering design workshops. During these workshops students do bifocal modeling, computational modeling, digital fabrication, robotics and introductory electronics, computer programming, wood working, polymer casting and more. (p. 2)</p>

<p>Digital Design Drawing Data Using digital pens and paper, I will capture continuous inking streams of student drawings. This will enable me to have the full evolution of their designs in a high precision fashion. These drawings will be aligned with speech data. (p. 2)</p>

<p>Student Gaze Data, Explanations and NetLogo logs – students will be asked to participate in a pair of studies in which they explore STEM phenomena in Netlogo, an agent based modeling environment. I will log their gaze, verbal explanations and Netlogo actions through synchronous data capture. (p. 2)</p>

<p><em>Student Wifi-based Localization</em> – Using a custom Android application, I will capture student’s relative locations at halfsecond increments as they move around the lab. This information will be useful for studying relative student collaboration, as well as for bootstrapping other data streams. (p. 2)</p>

<p><em>Student Motivation and Sentiment</em> – This data will come from a mobile phone survey platform. Students will be asked multiple choice, likert scale and free response questions through periodic polling. This information is useful for grounding some of the interpretations that I make from looking at students speech and actions near the time of polling. (p. 2)</p>

<p><em>Student Dialogue Capture</em> – An array of microphones arrays, lapel and head-mounted microphones will be used to capture student dialogue throughout the lab. I am still trying to find the best solution to do this synchronously, in a relatively large space, and for a large number of users. (p. 2)</p>

<p><em>Student Location Capture</em> – Using Kinect Sensors and a Teachscape Panoramic Camera, I will capture student location and actions. (p. 2)</p>


  <footer>
  
<nav class="post-nav">
  <span class="nav-prev">&larr; <a href="/notes/2014-09-25-xiong15092011/">Notes: Xiong - 2011 - Bayesian prediction of tissue-regulated splicing using RNA sequence and cellular context</a></span>
  <span class="nav-next"><a href="/notes/2016-01-28-woodruff1997/">Notes: Woodruff, E., &amp; Meyer, K. (1997). Explanations from intra- and inter-group discourse</a> &rarr;</span>
</nav>
<script type="text/javascript">
document.addEventListener('keyup', function(e) {
  if (e.target.nodeName.toUpperCase() != 'BODY') return;
  var url = false;
  if (e.which == 37) {  
    
    url = '\/notes\/2014-09-25-xiong15092011\/';
    
  } else if (e.which == 39) {  
    
    url = '\/notes\/2016-01-28-woodruff1997\/';
    
  }
  if (url) window.location = url;
});
</script>



<section class="comments">
  <div id="disqus_thread"></div>
  <script src="/js/disqusloader.min.js"></script>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var disqus_js = '//meefen.disqus.com/embed.js';
    
    if (location.hash.match(/^#comment/)) {
      var d = document, s = d.createElement('script');
      s.src = disqus_js; s.async = true;
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    } else {
      disqusLoader('#disqus_thread', {
        scriptUrl: disqus_js, laziness: 0, disqusConfig: disqus_config
      });
    }
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>







  

  
  <hr>
  <div class="copyright">&copy; <a href="http://meefen.github.io/">Bodong Chen</a> 2015-2018 | <a href="https://github.com/meefen">Github</a> | <a href="https://twitter.com/bod0ng">Twitter</a></div>
  
  </footer>
  </article>
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-50108133-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>


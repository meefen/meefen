<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>Notes: Laufer - 2013 - Lexical Frequency Profiles - Bodong Chen</title>
    <meta property="og:title" content="Notes: Laufer - 2013 - Lexical Frequency Profiles - Bodong Chen">
    

    
      
    

    

    
    

    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
<link rel="stylesheet" href="/css/custom.css" />

  </head>

  
  <body class="notes">
    <header class="masthead">
      <h1><a href="/">Bodong Chen</a></h1>

<p class="tagline">Crisscross Landscapes</p>

      <nav class="menu">
        <input id="menu-check" type="checkbox" />
        <label id="menu-label" for="menu-check" class="unselectable">
          <span class="icon close-icon">✕</span>
          <span class="icon open-icon">☰</span>
          <span class="text">Menu</span>
        </label>
        <ul>
        
        
        <li><a href="/">Home</a></li>
        
        <li><a href="/blog/">Blog</a></li>
        
        <li><a href="/cv/">Publications</a></li>
        
        <li><a href="/notes/">Open Scholar</a></li>
        
        <li><a href="/teaching/">Teaching</a></li>
        
        <li><a href="/%E5%8D%9A%E5%AE%A2/">博客</a></li>
        
        <li><a href="/index.xml">Subscribe</a></li>
        
        
        </ul>
      </nav>
    </header>

    <article class="main">
      <header class="title">
      
<h1>Notes: Laufer - 2013 - Lexical Frequency Profiles</h1>

<h3>
  0001-01-01</h3>
<hr>


      </header>





<h2 id="references">References</h2>

<p><strong>Citekey</strong>: @laufer2013lexical</p>

<p>Laufer B (2013). “Lexical Frequency Profiles.” In Chapelle CA (ed.),
<em>The Encyclopedia of Applied Linguistics</em>. Blackwell Publishing Ltd.</p>

<h2 id="notes">Notes</h2>

<p>A encyclopedia entry about Lexical Frequency Profiles. Laufer explains the assumption, concepts, and tools nicely.</p>

<ul>
<li>Assumption: A large number of infrequent words would make a text more difficult to understand. More advanced learners could use a higher percentage of infrequent vocabulary than learners of lower proficiencies.</li>
<li>Concepts: <em>Knowledge</em> is taken to be the information about a word which is stored and interconnected in the mental lexicon. <em>Use</em>, on the other hand, is the choice of speakers or writers to put their lexical knowledge into practice.</li>
<li>Tools: <a href="http://www.victoria.ac.nz/lals/staff/paul-nation.aspx">Range</a> and <a href="http://www.lognostics.co.uk/tools/index.htm">P_lex</a></li>
</ul>

<h2 id="highlights">Highlights</h2>

<p>How do we know that people use rich and sophisticated vocabulary in their writing? (p. 1)</p>

<p>Laufer and Nation (1995) proposed that the vocabulary richness of a text could be measured by a quantitative index called the lexical frequency profile (LFP) which uses the proportion of frequent versus nonfrequent vocabulary in the text. (p. 1)</p>

<p>The index can be calculated by a special computer program, Range, available on Paul Nation’s homepage (<a href="http://www.victoria.ac.nz/lals/staff/paul-nation.aspx">http://www.victoria.ac.nz/lals/staff/paul-nation.aspx</a>) (p. 1)</p>

<p>The basic assumption was that a large number of infrequent words would make a text more difficult to understand. (p. 1)</p>

<p>They found that the LFP was stable for compositions written by the same students on different topics, as long as these were of a general nature and did not involve infrequently used jargon words. (p. 1)</p>

<p>They also found that the profile discriminated between learners of different language proficiencies. More advanced learners could use a higher percentage of infrequent vocabulary than learners of lower proficiencies. (p. 1)</p>

<p>Nowadays, a more detailed lexical profile can be performed using the Range program on Nation’s site or VocabProfile BNC 20 on Cobb’s site. The text is matched against 20 frequency lists which were developed on the basis of the British National Corpus (BNC). The resulting analysis shows the number and the percentage of words at each 1,000 of the 20 lists of 20 thousands words. (p. 2)</p>

<p>The LFP is basically a measure of lexical use in writing, which can be distinguished from lexical knowledge. Knowledge is taken to be the information about a word which is stored and interconnected in the mental lexicon, for example, the spoken and written form, grammatical properties, different meanings, and connections with other words. Use, on the other hand, is the choice of speakers or writers to put their lexical knowledge into practice. In particular, use should be distinguished from active knowledge. Active knowledge is associated with speaking and writing and implies that we can retrieve the appropriate spoken or written word form when prompted to do so. For example, when asked to translate an L1 word into L2, we are asked to demonstrate our active knowledge. Use, however, has to do with producing words at one’s free will, as is the case of a composition. (p. 2)</p>

<p>Thus, LFP is one of the quantitative measures of lexical proficiency. There are additional quantitative measures that test other aspects of lexical proficiency: passive vocabulary size, for example, Nation and Beglar (2007), active vocabulary size, for example, Laufer and Nation (1999), both passive and active (Laufer &amp; Goldstein, 2004; Laufer, Elder, Hill, &amp; Congdon, 2004), and speed of meaning recognition (Laufer &amp; Nation, 2001). (p. 2)</p>

<p>Another profile of lexis is P_Lex developed by Paul Meara and available for use online (<a href="http://www.lognostics.co.uk/tools/index.htm">http://www.lognostics.co.uk/tools/index.htm</a>). The profile is similar to the LFP in its underlying assumptions (p. 3)</p>

<p>However, it is different from the LFP in several respects. Infrequent vocabulary is considered vocabulary that is not in the first most common 1,000 words. The analysis is performed by dividing a text into segments of 10 words each, calculating the number of beyond 1,000 words for each segment and turning these data into a single figure known as the lambda. A higher lambda indicates a higher proportion of infrequent words (for the mathematics of calculating the lambda, see Meara &amp; Bell, 2001). P_Lex is also claimed to work well with shorter texts than those suggested for the LFP analysis, that is, texts shorter than 200 words. (p. 3)</p>

<p>There are two major shortcomings of lexical profiles. First, they do not distinguish between homonyms (words with unrelated meanings, e.g., “bank,” “pupil”) and yet different meanings may belong to different frequency bands. Second, the profiles do not “recognize” multi-word units such as “as a matter of fact,” “of course,” “make up one’s mind.” Instead of listing them as single units, the profilers decompose them into separate words, for example, “of” and “course.” (p. 3)</p>

<h3 id="references-1">References</h3>

<p>Coxhead, A. (2000). A new Academic Word List. TESOL Quarterly, 34(2), 213–38. (p. 3)</p>

<p>Horst, M., &amp; Collins, L. (2006). From faible to strong: How does their vocabulary grow? The Canadian Modern Language Review, 63(1), 83–106. (p. 3)</p>

<p>Laufer, B. (1994). The lexical profile of second language writing: Does it change over time? RELC Journal, 25(2), 21–33. (p. 3)</p>


  <footer>
  
<nav class="post-nav">
  <span class="nav-prev">&larr; <a href="/notes/2015-10-01-denner2011/">Notes: Lee. (2011). Computational thinking for youth in practice</a></span>
  <span class="nav-next"><a href="/notes/2014-10-30-laufer01121994/">Notes: Laufer - 1994 - The Lexical Profile of Second Language Writing: Does It Change Over Time?</a> &rarr;</span>
</nav>
<script type="text/javascript">
document.addEventListener('keyup', function(e) {
  if (e.target.nodeName.toUpperCase() != 'BODY') return;
  var url = false;
  if (e.which == 37) {  
    
    url = '\/notes\/2015-10-01-denner2011\/';
    
  } else if (e.which == 39) {  
    
    url = '\/notes\/2014-10-30-laufer01121994\/';
    
  }
  if (url) window.location = url;
});
</script>



<section class="comments">
  <div id="disqus_thread"></div>
  <script src="/js/disqusloader.min.js"></script>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var disqus_js = '//meefen.disqus.com/embed.js';
    
    if (location.hash.match(/^#comment/)) {
      var d = document, s = d.createElement('script');
      s.src = disqus_js; s.async = true;
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    } else {
      disqusLoader('#disqus_thread', {
        scriptUrl: disqus_js, laziness: 0, disqusConfig: disqus_config
      });
    }
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>







  

  
  <hr>
  <div class="copyright">&copy; <a href="http://bodong.ch/">Bodong Chen</a> 2015-2018 | <a href="https://github.com/meefen">Github</a> | <a href="https://twitter.com/bod0ng">Twitter</a></div>
  
  </footer>
  </article>
  
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-50108133-1', 'auto');
ga('send', 'pageview');
</script>

  </body>
</html>

